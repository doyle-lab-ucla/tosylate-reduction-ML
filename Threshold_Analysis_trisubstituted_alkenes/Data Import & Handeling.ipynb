{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d18d593",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, pickle, datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import copy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest,f_regression,mutual_info_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression,Ridge,ElasticNetCV,ElasticNet,Lars,LassoCV,RidgeCV,LarsCV,LassoLarsCV,LassoLarsIC,OrthogonalMatchingPursuitCV,OrthogonalMatchingPursuit\n",
    "from sklearn.manifold import TSNE,MDS\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RepeatedKFold,LeaveOneOut,cross_val_score,cross_validate\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#from sklearn import tree\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import multiprocessing\n",
    "nproc = max([1,multiprocessing.cpu_count()-2])\n",
    "from joblib import Parallel,delayed\n",
    "from statistics import mean\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import loo_q2 as loo\n",
    "\n",
    "randomstate = 42\n",
    "\n",
    "def plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"y\",loo_pred=[]):\n",
    "    y_orig_min = np.min(np.hstack((y_train,y_test)))\n",
    "    y_pred_min = np.min(np.hstack((y_pred_train,y_pred_test)))\n",
    "    y_orig_max = np.max(np.hstack((y_train,y_test)))\n",
    "    y_pred_max = np.max(np.hstack((y_pred_train,y_pred_test)))\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)\n",
    "           \n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    # plt.plot(np.linspace(y_orig_min-delta_x,y_orig_max+delta_x), np.linspace(y_orig_min-delta_x,y_orig_max+delta_x),color=\"grey\")\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\".\",facecolor='none',s=200)\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"black\",marker=\".\",s=200) # ,alpha=0.6\n",
    "    plt.scatter(y_test,y_pred_test,label=\"test\",color='red',marker=\".\",linewidth=3, s=200)     #,alpha=0.25  \"#8da9f5\"\n",
    "    plt.plot(y_train,yy_fit_line,color=\"darkgrey\",linestyle='--',dashes=[5,15]) #,alpha=0.2\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.xlabel(label+\" measured\",fontsize=18, fontweight='bold')\n",
    "    plt.ylabel(label+\" predicted\",fontsize=18, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    \n",
    "    plt.gca().spines['right'].set_color('none')\n",
    "    plt.gca().spines['top'].set_color('none')\n",
    "    \n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav, dpi=300, bbox_inches='tight', transparent=True)\n",
    "        \n",
    "def r2_val(y_test,y_pred_test,y_train):\n",
    "    \"\"\"Calculates the external R2 pred as described:\n",
    "    https://pdfs.semanticscholar.org/4eb2/5ff5a87f2fd6789c5b9954eddddfd1c59dab.pdf\"\"\"\n",
    "    y_resid = y_pred_test - y_test\n",
    "    SS_resid = np.sum(y_resid**2)\n",
    "    y_var = y_test - np.mean(y_train)\n",
    "    SS_total = np.sum(y_var**2)\n",
    "    r2_validation = 1-SS_resid/SS_total\n",
    "    return(r2_validation)\n",
    "\n",
    "def repeated_k_fold(X_train,y_train,reg = LinearRegression(), k=3, n=100):\n",
    "    \"\"\"Reapeated k-fold cross-validation. \n",
    "    For each of n repeats, the (training)data is split into k folds. \n",
    "    For each fold, this part of the data is predicted using the rest. \n",
    "    Once this is done for all k folds, the coefficient of determination (R^2) of the predictions of all folds combined (= the complete data set) is evaluated\n",
    "    This is repeated n times and all n R^2 are returned for averaging/further analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n)\n",
    "    r2_scores = []\n",
    "    y_validations,y_predictions = np.zeros((np.shape(X_train)[0],n)),np.zeros((np.shape(X_train)[0],n))\n",
    "    foldcount = 0\n",
    "    for i,foldsplit in enumerate(rkf.split(X_train)):\n",
    "        fold, rep = i%k, int(i/k) # Which of k folds. Which of n repeats\n",
    "        model = reg.fit(X_train[foldsplit[0]],y_train[foldsplit[0]]) # foldsplit[0]: k-1 training folds\n",
    "        y_validations[foldcount:foldcount+len(foldsplit[1]),rep] = y_train[foldsplit[1]] # foldsplit[1]: validation fold\n",
    "        y_predictions[foldcount:foldcount+len(foldsplit[1]),rep]  = model.predict(X_train[foldsplit[1]])\n",
    "        foldcount += len(foldsplit[1])\n",
    "        if fold+1==k:\n",
    "            foldcount = 0\n",
    "    r2_scores = np.asarray([metrics.r2_score(y_validations[:,rep],y_predictions[:,rep]) for rep in range(n)])\n",
    "    return(r2_scores)\n",
    "\n",
    "###removes zeros from the front of a number (as a string) to make them comparable regardless of source format\n",
    "def remove_prefix_zeros(number):\n",
    "    temp=number\n",
    "    loop=True\n",
    "    while(loop):\n",
    "        if temp.startswith('0'):\n",
    "            temp=temp[1:]\n",
    "        else:\n",
    "            loop=False\n",
    "            \n",
    "    try:\n",
    "        temp=float(temp)\n",
    "        temp=int(temp)\n",
    "        temp=str(temp)\n",
    "    except ValueError:\n",
    "        temp=str(temp)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "import random\n",
    "insu = [\"yikes. that's ass.\",\"LMAO do not publish this what are you doing\",\"oof.\",\"that's a rough one\",\"I'm embarassed to even print this, but here it is:\",\"more disappointing than an unsalted pretzel\",\"this model makes onions cry\",\"did you get this model from Joe?\",\"remember, these stats aren't an insult, they're just describing your model\",\"this model reminds me - I gotta take out the trash\",\"don't worry - the first 40 years of modeling are always the hardest\",\"this model has miles to go before it reaches mediocre\",\"the bad model store called. they're running out of your models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e65a70",
   "metadata": {},
   "source": [
    "# Import excel sheets & format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b4445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate computational descriptor and experimental data files, skip cell below if using two different excel sheets\n",
    "comp_file = \"descriptors\" \n",
    "comp_sheet = \"DFT_data\" \n",
    "num_par = 190\n",
    "par_start_col = 1   # 0-indexed\n",
    "comp_num_samples = 1560 \n",
    "y_label_col_comp = 0  # 0-indexed\n",
    "\n",
    "exp_file = \"trisub_TS4_ligand_prediction\" \n",
    "exp_sheet = \"Sheet2\"\n",
    "exp_num_samples = 242 \n",
    "response_col = 2 # 0-indexed\n",
    "y_label_col_exp = 0  # 0-indexed\n",
    "\n",
    "compinp = pd.read_excel(\"./InputData/\"+comp_file+\".xlsx\",comp_sheet,header=0,index_col=y_label_col_comp,nrows=comp_num_samples+1,usecols=list(range(0,(num_par+par_start_col))))\n",
    "compinp.index = [remove_prefix_zeros(i) for i in compinp.index.map(str)]\n",
    "expinp = pd.read_excel(\"./InputData/\"+exp_file+\".xlsx\",exp_sheet,header=2,index_col=y_label_col_exp,nrows=exp_num_samples,usecols=list(range(0,response_col+1)))\n",
    "expinp.index = [remove_prefix_zeros(i) for i in expinp.index.map(str)]\n",
    "\n",
    "expinp.dtypes\n",
    "\n",
    "xlabelrow = True\n",
    "verbose = True\n",
    "\n",
    "X_names = list(compinp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "X_labels = list(compinp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "compinp.drop(index=compinp.index[0],inplace=True)\n",
    "X_all = np.asarray(compinp[X_labels],dtype=np.float)\n",
    "y_labels_comp = np.asarray(list(compinp.index),dtype=str)\n",
    "compnan = np.isnan(X_all).any(axis=1)\n",
    "y_labels_comp,X_all = y_labels_comp[~compnan],X_all[~compnan]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "\n",
    "resp_label = list(expinp.columns)[response_col-1]\n",
    "y = np.asarray(expinp.iloc[:,response_col-1],dtype=np.float)\n",
    "y_labels_exp = np.asarray(list(expinp.index),dtype=str)\n",
    "\n",
    "mask_y = y.nonzero()[0]\n",
    "mask_y = ~np.isnan(y)\n",
    "mask_X = np.array([True if i in y_labels_comp else False for i in y_labels_exp])\n",
    "mask = mask_y&mask_X\n",
    "print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "y = y[np.array(mask)]\n",
    "y_labels = y_labels_exp[np.array(mask)]\n",
    "y_labels_int = [int(x) for x in y_labels]\n",
    "y_labels_dict = dict(zip(range(len(y_labels)),y_labels_int))\n",
    "\n",
    "X = np.asarray(compinp.loc[y_labels],dtype=np.float)\n",
    "\n",
    "del(compinp)\n",
    "del(expinp)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Shape X (all): {}\".format(X_all.shape))\n",
    "    print(\"Shape X (exp): {}\".format(X.shape))\n",
    "    print(\"Shape y (exp): {}\".format(y.shape)) \n",
    "    print(\"Shape labels (exp): {}\".format(y_labels.shape)) \n",
    "    print(\"First X (exp) cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X (exp) cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label exp: {}\".format(y_labels[-1]))\n",
    "    print(\"Last label comp: {}\".format(y_labels_comp[-3:]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all data in a single file\n",
    "excel_file =\"trisub_TS4_ligand_prediction\" \n",
    "excel_sheet = \"full_features_clean\" #\"singlesub\" #\"no_NH_no_diffaryl\" \n",
    "num_par = 190 #190 \n",
    "par_start_col = 7 # 0-indexed\n",
    "num_samples = 241 #68 #24 #34 \n",
    "response_col = 2 #2   # 0-indexed\n",
    "y_label_col = 0    # 0-indexed\n",
    "\n",
    "apply_mask = True # remove samples with empty response\n",
    "verbose = True\n",
    "xlabelrow = True\n",
    "\n",
    "\n",
    "inp = pd.read_excel(\"./InputData/\"+excel_file+\".xlsx\",excel_sheet,header=1,index_col=y_label_col,nrows=num_samples+int(xlabelrow),\n",
    "                    usecols=list(range(0,(num_par+par_start_col))))\n",
    "display(inp)\n",
    "print(inp.dtypes)\n",
    "\n",
    "if xlabelrow:\n",
    "    X_names = list(inp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "    inp.drop(index=inp.index[0],inplace=True)\n",
    "else:\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    X_names = X_labels\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "y = np.asarray(inp[resp_label],dtype=np.float)\n",
    "X = np.asarray(inp[X_labels],dtype=np.float)\n",
    "y_labels = np.asarray(list(inp.index),dtype=str)\n",
    "y_labels_comp= y_labels\n",
    "\n",
    "if apply_mask:\n",
    "    mask = y.nonzero()[0]\n",
    "    mask = ~np.isnan(y)\n",
    "    print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "    print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "    X = X[np.array(mask)]\n",
    "    y = y[np.array(mask)]\n",
    "    y_labels = y_labels[np.array(mask)]\n",
    "X_all = X\n",
    "if verbose:\n",
    "    print(\"Shape X: {}\".format(X.shape))\n",
    "    print(\"Shape y: {}\".format(y.shape)) \n",
    "    print(\"Shape labels: {}\".format(y_labels.shape)) \n",
    "    print(\"First X cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label: {}\".format(y_labels[-1]))\n",
    "    #print(inp.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
